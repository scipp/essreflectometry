{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divergent data reduction for Amor\n",
    "\n",
    "In this notebook, we will look at how to use the `essreflectometry` package with Sciline,\n",
    "for reflectometry data collected from the PSI instrument [Amor](https://www.psi.ch/en/sinq/amor) in [divergent beam mode](https://www.psi.ch/en/sinq/amor/selene).\n",
    "\n",
    "This notebook shows the basics of computing reduced results for a set of runs and saving them to Orso file format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "import warnings\n",
    "import scipp as sc\n",
    "from ess import amor\n",
    "from ess.amor import data  # noqa: F401\n",
    "from ess.reflectometry.types import *\n",
    "from ess.amor.types import *\n",
    "from ess.reflectometry import batch_compute\n",
    "\n",
    "# The files used in this tutorial have some issues that makes scippnexus\n",
    "# raise warnings when loading them. To avoid noise in the notebook the warnings are silenced.\n",
    "warnings.filterwarnings('ignore', 'Failed to convert .* into a transformation')\n",
    "warnings.filterwarnings('ignore', 'Invalid transformation')\n",
    "warnings.filterwarnings('ignore', 'invalid value encountered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and configure the workflow\n",
    "\n",
    "We begin by creating the Amor workflow object which is a skeleton for reducing Amor data,\n",
    "with pre-configured steps, and then set the missing parameters which are specific to each experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = amor.AmorWorkflow()\n",
    "workflow[SampleSize[SampleRun]] = sc.scalar(10.0, unit='mm')\n",
    "workflow[SampleSize[ReferenceRun]] = sc.scalar(10.0, unit='mm')\n",
    "\n",
    "workflow[ChopperPhase[ReferenceRun]] = sc.scalar(-7.5, unit='deg')\n",
    "workflow[ChopperPhase[SampleRun]] = sc.scalar(-7.5, unit='deg')\n",
    "\n",
    "workflow[WavelengthBins] = sc.geomspace('wavelength', 2.8, 12.5, 2001, unit='angstrom')\n",
    "\n",
    "# The YIndexLimits and ZIndexLimits define ranges on the detector where\n",
    "# data is considered to be valid signal.\n",
    "# They represent the lower and upper boundaries of a range of pixel indices.\n",
    "workflow[YIndexLimits] = sc.scalar(11), sc.scalar(41)\n",
    "workflow[ZIndexLimits] = sc.scalar(80), sc.scalar(370)\n",
    "workflow[BeamDivergenceLimits] = (\n",
    "    sc.scalar(-0.75, unit='deg'),\n",
    "    sc.scalar(0.75, unit='deg'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the reference run\n",
    "\n",
    "The reference represents the intensity reflected by the super-mirror.\n",
    "The same run is used for normalizing all sample runs,\n",
    "and it thus only needs to be reduced once.\n",
    "\n",
    "In this subsection, we reduce the reference run and cache it onto the workflow to speed-up subsequent processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow[Filename[ReferenceRun]] = amor.data.amor_run(614)\n",
    "\n",
    "# The sample rotation value in the file is slightly off, so we set it manually\n",
    "workflow[SampleRotationOffset[ReferenceRun]] = sc.scalar(0.05, unit='deg')\n",
    "\n",
    "# Set the result back onto the pipeline to cache it\n",
    "workflow[ReducedReference] = workflow.compute(ReducedReference)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing sample reflectivity from batch reduction\n",
    "\n",
    "We now compute the sample reflectivity from 4 runs that used different sample rotation angles.\n",
    "The measurements at different rotation angles cover different ranges of $Q$.\n",
    "\n",
    "We use the `batch_compute` function which makes it easy to process multiple runs at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = {\n",
    "    '608': {\n",
    "        SampleRotationOffset[SampleRun]: sc.scalar(0.05, unit='deg'),\n",
    "        Filename[SampleRun]: amor.data.amor_run(608),\n",
    "    },\n",
    "    '609': {\n",
    "        SampleRotationOffset[SampleRun]: sc.scalar(0.05, unit='deg'),\n",
    "        Filename[SampleRun]: amor.data.amor_run(609),\n",
    "    },\n",
    "    '610': {\n",
    "        SampleRotationOffset[SampleRun]: sc.scalar(0.05, unit='deg'),\n",
    "        Filename[SampleRun]: amor.data.amor_run(610),\n",
    "    },\n",
    "    '611': {\n",
    "        SampleRotationOffset[SampleRun]: sc.scalar(0.05, unit='deg'),\n",
    "        Filename[SampleRun]: amor.data.amor_run(611),\n",
    "    },\n",
    "}\n",
    "\n",
    "# Compute R(Q) for all runs\n",
    "r_of_q = batch_compute(workflow, runs, target=ReflectivityOverQ)\n",
    "r_of_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.plot(r_of_q.hist(), norm='log', vmin=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the reflectivity curves to overlap\n",
    "\n",
    "In case we know the curves are have been scaled by different factors (that are constant in Q) it can be useful to scale them so they overlap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_r = batch_compute(\n",
    "    workflow,\n",
    "    runs,\n",
    "    target=ReflectivityOverQ,\n",
    "    scale_to_overlap=(\n",
    "        sc.scalar(0.01, unit='1/angstrom'),\n",
    "        sc.scalar(0.014, unit='1/angstrom'),\n",
    "    ),\n",
    ")\n",
    "\n",
    "sc.plot(scaled_r.hist(), norm='log', vmin=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data\n",
    "\n",
    "We can save the computed $I(Q)$ to an [ORSO](https://www.reflectometry.org) [.ort](https://github.com/reflectivity/file_format/blob/master/specification.md) file using the [orsopy](https://orsopy.readthedocs.io/en/latest/index.html) package.\n",
    "\n",
    "First, we need to collect the metadata for that file.\n",
    "To this end, we insert a parameter to indicate the creator of the processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ess.reflectometry import orso\n",
    "from orsopy import fileio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow[orso.OrsoCreator] = orso.OrsoCreator(\n",
    "    fileio.base.Person(\n",
    "        name='Max Mustermann',\n",
    "        affiliation='European Spallation Source ERIC',\n",
    "        contact='max.mustermann@ess.eu',\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build our ORSO dataset from the computed $I(Q)$ and the ORSO metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iofq_datasets = batch_compute(\n",
    "    workflow,\n",
    "    runs,\n",
    "    target=orso.OrsoIofQDataset,\n",
    "    scale_to_overlap=(\n",
    "        sc.scalar(0.01, unit='1/angstrom'),\n",
    "        sc.scalar(0.014, unit='1/angstrom'),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also add the URL of this notebook to make it easier to reproduce the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in iofq_datasets.values():\n",
    "    ds.info.reduction.script = (\n",
    "        'https://scipp.github.io/essreflectometry/user-guide/amor/amor-reduction-simple.html'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can save the data to a file.\n",
    "Note that `iofq_datasets` contains [orsopy.fileio.orso.OrsoDataset](https://orsopy.readthedocs.io/en/latest/orsopy.fileio.orso.html#orsopy.fileio.orso.OrsoDataset)s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileio.orso.save_orso(\n",
    "    datasets=list(iofq_datasets.values()), fname='amor_reduced_iofq.ort'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the first 50 lines of the file to inspect the metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head amor_reduced_iofq.ort -n50"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
