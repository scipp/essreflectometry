{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divergent data reduction for Amor - advanced\n",
    "\n",
    "In this notebook, we will look at how to use the `essreflectometry` package with Sciline, for reflectometry data collected from the PSI instrument [Amor](https://www.psi.ch/en/sinq/amor) in [divergent beam mode](https://www.psi.ch/en/sinq/amor/selene).\n",
    "\n",
    "We will begin by importing the modules that are necessary for this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "import warnings\n",
    "import scipp as sc\n",
    "from ess import amor\n",
    "from ess.amor import data  # noqa: F401\n",
    "from ess.reflectometry.types import *\n",
    "from ess.amor.types import *\n",
    "from ess.reflectometry import batch_processor\n",
    "\n",
    "# The files used in this tutorial have some issues that makes scippnexus\n",
    "# raise warnings when loading them. To avoid noise in the notebook the warnings are silenced.\n",
    "warnings.filterwarnings('ignore', 'Failed to convert .* into a transformation')\n",
    "warnings.filterwarnings('ignore', 'Invalid transformation')\n",
    "warnings.filterwarnings('ignore', 'invalid value encountered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and configure the workflow\n",
    "\n",
    "We begin by creating the Amor workflow object which is a skeleton for reducing Amor data,\n",
    "with pre-configured steps, and then set the missing parameters which are specific to each experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = amor.AmorWorkflow()\n",
    "workflow[SampleSize[SampleRun]] = sc.scalar(10.0, unit='mm')\n",
    "workflow[SampleSize[ReferenceRun]] = sc.scalar(10.0, unit='mm')\n",
    "\n",
    "workflow[ChopperPhase[ReferenceRun]] = sc.scalar(-7.5, unit='deg')\n",
    "workflow[ChopperPhase[SampleRun]] = sc.scalar(-7.5, unit='deg')\n",
    "\n",
    "workflow[WavelengthBins] = sc.geomspace('wavelength', 2.8, 12.5, 2001, unit='angstrom')\n",
    "\n",
    "# The YIndexLimits and ZIndexLimits define ranges on the detector where\n",
    "# data is considered to be valid signal.\n",
    "# They represent the lower and upper boundaries of a range of pixel indices.\n",
    "workflow[YIndexLimits] = sc.scalar(11), sc.scalar(41)\n",
    "workflow[ZIndexLimits] = sc.scalar(80), sc.scalar(370)\n",
    "workflow[BeamDivergenceLimits] = (\n",
    "    sc.scalar(-0.75, unit='deg'),\n",
    "    sc.scalar(0.75, unit='deg'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.visualize(ReflectivityOverQ, graph_attr={'rankdir': 'LR'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching the reference result\n",
    "\n",
    "The reference result (used for normalizing the sample data) only needs to be computed once.\n",
    "It represents the intensity reflected by the super-mirror.\n",
    "\n",
    "We compute it using the pipeline and thereafter set the result back on the original pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow[Filename[ReferenceRun]] = amor.data.amor_run(614)\n",
    "# The sample rotation value in the file is slightly off, so we set it manually\n",
    "workflow[SampleRotationOffset[ReferenceRun]] = sc.scalar(0.05, unit='deg')\n",
    "\n",
    "reference_result = workflow.compute(ReducedReference)\n",
    "# Set the result back onto the pipeline to cache it\n",
    "workflow[ReducedReference] = reference_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we now visualize the pipeline again, we can see that the reference is not re-computed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.visualize(ReflectivityOverQ, graph_attr={'rankdir': 'LR'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing sample reflectivity from batch reduction\n",
    "\n",
    "We now compute the sample reflectivity from 4 runs that used different sample rotation angles.\n",
    "The measurements at different rotation angles cover different ranges of $Q$.\n",
    "\n",
    "We set up a batch reduction helper (using the `batch_processor` function) which makes it easy to process multiple runs at once.\n",
    "\n",
    "In this tutorial we use some Amor data files we have received.\n",
    "The file paths to the tutorial files are obtained by calling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amor.data.amor_run(608)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you encounter `amor.data.amor_run` you should imagining replacing that with a path to your own dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = {\n",
    "    '608': {\n",
    "        # The sample rotation values in the files are slightly off, so we replace\n",
    "        # them with corrected values.\n",
    "        SampleRotationOffset[SampleRun]: sc.scalar(0.05, unit='deg'),\n",
    "        Filename[SampleRun]: amor.data.amor_run(608),\n",
    "    },\n",
    "    '609': {\n",
    "        SampleRotationOffset[SampleRun]: sc.scalar(0.05, unit='deg'),\n",
    "        Filename[SampleRun]: amor.data.amor_run(609),\n",
    "    },\n",
    "    '610': {\n",
    "        SampleRotationOffset[SampleRun]: sc.scalar(0.05, unit='deg'),\n",
    "        Filename[SampleRun]: amor.data.amor_run(610),\n",
    "    },\n",
    "    '611': {\n",
    "        SampleRotationOffset[SampleRun]: sc.scalar(0.05, unit='deg'),\n",
    "        Filename[SampleRun]: amor.data.amor_run(611),\n",
    "    },\n",
    "}\n",
    "\n",
    "batch = batch_processor(workflow, runs)\n",
    "\n",
    "# Compute R(Q) for all runs\n",
    "reflectivity = batch.compute(ReflectivityOverQ)\n",
    "sc.plot(reflectivity.hist(), norm='log', vmin=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.visualize(ReflectivityOverQ, graph_attr={'rankdir': 'LR'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the reflectivity curves to overlap\n",
    "\n",
    "In case we know the curves are have been scaled by different factors (that are constant in Q) it can be useful to scale them so they overlap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache intermediate result to avoid re-loading the data\n",
    "batch[ReducibleData[SampleRun]] = batch.compute(ReducibleData[SampleRun])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ess.reflectometry.tools import scale_for_reflectivity_overlap\n",
    "\n",
    "scaling = scale_for_reflectivity_overlap(\n",
    "    reflectivity,\n",
    "    critical_edge_interval=(\n",
    "        sc.scalar(0.01, unit='1/angstrom'),\n",
    "        sc.scalar(0.014, unit='1/angstrom'),\n",
    "    ),\n",
    ")\n",
    "\n",
    "scaled_r = reflectivity * scaling\n",
    "\n",
    "sc.plot(scaled_r.hist(), norm='log', vmin=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curves obtained from measurements at different angles can be combined to one common reflectivity curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ess.reflectometry.tools import combine_curves\n",
    "\n",
    "qbins = sc.geomspace('Q', 0.005, 0.4, 501, unit='1/angstrom')\n",
    "combined = combine_curves(scaled_r.hist(), qbins)\n",
    "combined.plot(norm='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some useful visualizations that can be used to troubleshoot the instrument.\n",
    "They typically operate on the `ReflectivityData`.\n",
    "\n",
    "The difference between `ReflectivityData` and `ReflectivityOverQ` is that `ReflectivityData` is not binned in $Q$, but instead has the same shape as the reference.\n",
    "\n",
    "Essentially it represents a \"reflectivity\" computed in every wavelength-detector coordinate (`z_index`) bin.\n",
    "This makes it easier to spot inhomogeneities and diagnose problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostics = batch.compute(ReflectivityOverZW)\n",
    "diagnostics['608'].hist().flatten(('blade', 'wire'), to='z').plot(norm='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a $(\\lambda, \\theta)$ map\n",
    "A good sanity check is to create a two-dimensional map of the counts in $\\lambda$ and $\\theta$ bins and make sure the triangles converge at the origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ess.reflectometry.figures import wavelength_theta_figure\n",
    "\n",
    "wavelength_theta_figure(\n",
    "    diagnostics.values(),\n",
    "    theta_bins=batch.compute(ThetaBins[SampleRun]).values(),\n",
    "    q_edges_to_display=(\n",
    "        sc.scalar(0.018, unit='1/angstrom'),\n",
    "        sc.scalar(0.113, unit='1/angstrom'),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot can be used to check if the value of the sample rotation angle $\\omega$ is correct. The bright triangles should be pointing back to the origin $\\lambda = \\theta = 0$. In the figure above the black lines are all passing through the origin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a $(Q, \\theta)$ map\n",
    "Another good sanity check is to create a two-dimensional map of the counts in $\\lambda$ and $Q$ and make sure the stripes are vertical. If they are not that could indicate that the `ChopperPhase` setting is incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ess.reflectometry.figures import q_theta_figure\n",
    "\n",
    "q_theta_figure(\n",
    "    diagnostics.values(),\n",
    "    theta_bins=batch.compute(ThetaBins[SampleRun]).values(),\n",
    "    q_bins=qbins,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the sample measurement to the reference on the detector\n",
    "\n",
    "Here we compare the raw number of counts on the detector for the sample measurement and the reference respectively.\n",
    "\n",
    "`z_index` is the $z-$detector coordinate, that is, the detector coordinate in the direction of the scattering angle $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ess.reflectometry.figures import wavelength_z_figure\n",
    "\n",
    "wf_608 = batch.workflows['608']\n",
    "\n",
    "wavelength_z_figure(\n",
    "    wf_608.compute(Sample), wavelength_bins=wf_608.compute(WavelengthBins), grid=False\n",
    ") + wavelength_z_figure(wf_608.compute(Reference), grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data\n",
    "\n",
    "We can save the computed $I(Q)$ to an [ORSO](https://www.reflectometry.org) [.ort](https://github.com/reflectivity/file_format/blob/master/specification.md) file using the [orsopy](https://orsopy.readthedocs.io/en/latest/index.html) package.\n",
    "\n",
    "First, we need to collect the metadata for that file.\n",
    "To this end, we insert a parameter to indicate the creator of the processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ess.reflectometry import orso\n",
    "from orsopy import fileio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[orso.OrsoCreator] = {\n",
    "    k: orso.OrsoCreator(\n",
    "        fileio.base.Person(\n",
    "            name='Max Mustermann',\n",
    "            affiliation='European Spallation Source ERIC',\n",
    "            contact='max.mustermann@ess.eu',\n",
    "        )\n",
    "    )\n",
    "    for k in runs\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the workflow for a single run (`'608'`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_608.visualize(orso.OrsoIofQDataset, graph_attr={'rankdir': 'LR'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to save the scaled results to the file\n",
    "batch[ReflectivityOverQ] = scaled_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build our ORSO dataset from the computed $I(Q)$ and the ORSO metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iofq_datasets = batch.compute(orso.OrsoIofQDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also add the URL of this notebook to make it easier to reproduce the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in iofq_datasets.values():\n",
    "    ds.info.reduction.script = (\n",
    "        'https://scipp.github.io/essreflectometry/user-guide/amor/amor-reduction.html'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can save the data to a file.\n",
    "Note that `iofq_datasets` contains [orsopy.fileio.orso.OrsoDataset](https://orsopy.readthedocs.io/en/latest/orsopy.fileio.orso.html#orsopy.fileio.orso.OrsoDataset)s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileio.orso.save_orso(\n",
    "    datasets=list(iofq_datasets.values()), fname='amor_reduced_iofq.ort'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the first 50 lines of the file to inspect the metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head amor_reduced_iofq.ort -n50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging multiple runs for the same sample rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = {\n",
    "    '608': {\n",
    "        # The sample rotation values in the files are slightly off, so we replace\n",
    "        # them with corrected values.\n",
    "        SampleRotationOffset[SampleRun]: sc.scalar(0.05, unit='deg'),\n",
    "        Filename[SampleRun]: amor.data.amor_run(608),\n",
    "    },\n",
    "    '609': {\n",
    "        SampleRotationOffset[SampleRun]: sc.scalar(0.05, unit='deg'),\n",
    "        Filename[SampleRun]: amor.data.amor_run(609),\n",
    "    },\n",
    "    '610': {\n",
    "        SampleRotationOffset[SampleRun]: sc.scalar(0.05, unit='deg'),\n",
    "        Filename[SampleRun]: amor.data.amor_run(610),\n",
    "    },\n",
    "    '611+612': {\n",
    "        SampleRotationOffset[SampleRun]: sc.scalar(0.05, unit='deg'),\n",
    "        Filename[SampleRun]: (\n",
    "            amor.data.amor_run(611),\n",
    "            amor.data.amor_run(612),\n",
    "        ),  # List of files means their event lists should be merged\n",
    "    },\n",
    "}\n",
    "\n",
    "batch = batch_processor(workflow, runs)\n",
    "\n",
    "# Compute R(Q) for all runs\n",
    "reflectivity = batch.compute(ReflectivityOverQ)\n",
    "sc.plot(reflectivity.hist(), norm='log', vmin=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.visualize(ReflectivityOverQ, graph_attr={'rankdir': 'LR'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_r = reflectivity * scale_for_reflectivity_overlap(\n",
    "    reflectivity,\n",
    "    critical_edge_interval=(\n",
    "        sc.scalar(0.01, unit='1/angstrom'),\n",
    "        sc.scalar(0.014, unit='1/angstrom'),\n",
    "    ),\n",
    ")\n",
    "\n",
    "sc.plot(scaled_r.hist(), norm='log', vmin=1e-5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
