{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Reduction of spin flip data from McStas simulation\n",
    "\n",
    "This notebook contains an example of polarized reflectometry data reduction.\n",
    "The dataset comes from a McStas simulation of the ESTIA instrument.\n",
    "\n",
    "\n",
    "Four samples were simulated:\n",
    "\n",
    "* `supermirror` - a perfect nonmagnetic supermirror\n",
    "* `magnetic_supermirror` - a magnetic supermirror with high reflectivity for one spin state and low reflectivity for the other\n",
    "* `magnetic_supermirror_2` - a magnetic supermirror with slightly different reflectivity curve than `magnetic_supermirror`\n",
    "* `spin_flip_sample` - a magnetic supermirror that also causes some incident neutrons to spin flip with 10% probability\n",
    "\n",
    "Each sample was measured for four different flipper settings `offoff`, `offon`, `onoff`, `onon`, corresponding to the polarizer and analyzer flipper setting.\n",
    "\n",
    "In the data reduction procedure  `supermirror` and `magnetic_supermirror_2` will be used to calibrate the parameters of the instrument."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "We start by importing packages and creating the workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib ipympl\n",
    "import scipp as sc\n",
    "\n",
    "from ess.reflectometry.types import *\n",
    "from ess.reflectometry.supermirror import CriticalEdge\n",
    "\n",
    "from ess.estia.types import *\n",
    "from ess.estia import EstiaMcStasWorkflow\n",
    "from ess.estia.data import (\n",
    "    estia_mcstas_spin_flip_example,\n",
    "    estia_mcstas_spin_flip_example_groundtruth,\n",
    "    estia_mcstas_spin_flip_example_download_all_to_cache,\n",
    "    estia_tof_lookup_table,\n",
    ")\n",
    "from ess.reflectometry.figures import wavelength_z_figure\n",
    "from ess.estia.mcstas import mcstas_wavelength_coordinate_transformation_graph\n",
    "\n",
    "from ess.polarization import (  # noqa: F401\n",
    "    Up, Down, ReducedSampleDataBySpinChannel, SupermirrorEfficiencyFunction, Polarizer, Analyzer, PolarizationAnalysisWorkflow,\n",
    "    SupermirrorWorkflow, SecondDegreePolynomialEfficiency, EfficiencyLookupTable\n",
    ")\n",
    "from ess.polarization.types import TotalPolarizationCorrectedData\n",
    "\n",
    "wf = EstiaMcStasWorkflow()\n",
    "wf[YIndexLimits]  = sc.scalar(35), sc.scalar(64)\n",
    "wf[ZIndexLimits] = sc.scalar(600), sc.scalar(930)\n",
    "wf[BeamDivergenceLimits] = sc.scalar(-0.75, unit='deg'), sc.scalar(0.75, unit='deg')\n",
    "wf[WavelengthBins] = sc.geomspace('wavelength', 4., 12, 700, unit='angstrom')\n",
    "wf[QBins] = sc.linspace('Q', 0.001, 0.1, 200, unit='1/angstrom')\n",
    "\n",
    "\n",
    "wf.insert( mcstas_wavelength_coordinate_transformation_graph )\n",
    "wf[TimeOfFlightLookupTableFilename] = estia_tof_lookup_table()\n",
    "\n",
    "# Reference sample is perfect supermirror with reflectivity = 1 everywhere\n",
    "wf[CriticalEdge] = sc.scalar(float('inf'), unit='1/angstrom')\n",
    "\n",
    "# There is no proton current data in the McStas files, here we just add some fake proton current\n",
    "# data to make the workflow run.\n",
    "wf[ProtonCurrent[SampleRun]] = sc.DataArray(\n",
    "    sc.array(dims=('time',), values=[]),\n",
    "    coords={'time': sc.array(dims=('time',), values=[], unit='s')})\n",
    "wf[ProtonCurrent[ReferenceRun]] = sc.DataArray(\n",
    "    sc.array(dims=('time',), values=[]),\n",
    "    coords={'time': sc.array(dims=('time',), values=[], unit='s')})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Download the data: (might take ~2 minutes depending on your internet connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "estia_mcstas_spin_flip_example_download_all_to_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Reducing the data\n",
    "\n",
    "First each dataset is loaded and reduced separately.\n",
    "The datasets are reduced \"as references\" or \"as samples\" depending on how they are supposed to be used.\n",
    "`supermirror` and `magnetic_supermirror_2` are used as references to calibrate the instrument, and `spin_flip_sample` and `magnetic_supermirror` are reduced as samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "references = {}\n",
    "for sample in (\n",
    "    'supermirror',\n",
    "    'magnetic_supermirror_2',\n",
    "):\n",
    "    references[sample] = []\n",
    "    for flipper_setting in ('offoff', 'offon', 'onoff', 'onon'):\n",
    "        w = wf.copy()\n",
    "        w[RawDetector[ReferenceRun]] = sc.io.load_hdf5(estia_mcstas_spin_flip_example(sample, flipper_setting))\n",
    "        references[sample].append(w.compute(ReducedReference))\n",
    "\n",
    "        # We need to unalign all coords of the references to use\n",
    "        # them in the calibration procedure\n",
    "        for c in references[sample][-1].coords:\n",
    "            references[sample][-1].coords.set_aligned(c, False)\n",
    "\n",
    "\n",
    "samples = {}\n",
    "for sample in (\n",
    "    'spin_flip_sample',\n",
    "    'magnetic_supermirror'\n",
    "):\n",
    "    samples[sample] = []\n",
    "    for flipper_setting in ('offoff', 'offon', 'onoff', 'onon'):\n",
    "        w = wf.copy()\n",
    "        w[RawDetector[SampleRun]] = sc.io.load_hdf5(estia_mcstas_spin_flip_example(sample, flipper_setting))\n",
    "        samples[sample].append(w.compute(ReducibleData[SampleRun]))\n",
    "\n",
    "        # We need to unalign all coords\n",
    "        for c in samples[sample][-1].coords:\n",
    "            samples[sample][-1].coords.set_aligned(c, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Here we load the ground truth reflectivity curves for the `up` respectively `down` spin state.\n",
    "Those will be used to compare to the computed reflectivity curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rdown = sc.io.load_hdf5(estia_mcstas_spin_flip_example_groundtruth('down'))\n",
    "Rup = sc.io.load_hdf5(estia_mcstas_spin_flip_example_groundtruth('up'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "To calibrate the workflow we estimate the polarization efficiency of the polarizer and the analyzer respectively.\n",
    "\n",
    "The calibration is performed on the wavelength-dependent intensity obtained by summing over a slice of the detector.\n",
    "We don't sum over the entire detector because the signal is best in the center region.\n",
    "In the lower part of the detector the reflectivity of the magnetic reference increases quickly to be the same as the reflectivity of the non magnetic supermirror reference.\n",
    "In that region we cannot distinguish between the spin states, so doing the calibration there is useless.\n",
    "In the top part of the detector the signal is lower and there is more noise.\n",
    "We don't want to make the region of the detecor we consider too small because then we will have too little signal.\n",
    "\n",
    "The trade of is that we only consider the region of the detector highlighted in the below figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength_z_figure(references['magnetic_supermirror_2'][0].assign_masks(\n",
    "    bad_region=sc.where(\n",
    "        (references['magnetic_supermirror_2'][0].coords['z_index'] < sc.scalar(21 * 32)) |\n",
    "        (references['magnetic_supermirror_2'][0].coords['z_index'] >= sc.scalar(25 * 32)),\n",
    "        sc.scalar(True),\n",
    "        sc.scalar(False)\n",
    "    )\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "The intensity is accumulated over each `blade` of the detector, corresponding to a relatively thin interval of scattering angle.\n",
    "In such a thin interval of scattering angle the reflectivity of the magnetic supermirror is roughly a function of wavelength, and this is what we need for the calibration to work well.\n",
    "\n",
    "From the procedure described above we obtain separate calibration results for each `blade` of the detector.\n",
    "The separate calibration values are combined using a weighted average where each calibration value is weighted by the inverse of its variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ess.estia.calibration import PolarizationCalibrationParameters\n",
    "\n",
    "\n",
    "calibration = PolarizationCalibrationParameters.from_reference_measurements(\n",
    "    [r['blade', 21:25].sum('wire').rebin(wavelength=sc.linspace('wavelength', 4, 10.7, 50, unit='angstrom')) for r in references['supermirror']],\n",
    "    [r['blade', 21:25].sum('wire').rebin(wavelength=sc.linspace('wavelength', 4, 10.7, 50, unit='angstrom')) for r in references['magnetic_supermirror_2']],\n",
    ")\n",
    "\n",
    "\n",
    "def weighted_mean(p, dim):\n",
    "    return ((p / sc.variances(p)).nanmean(dim) / ((1 / sc.variances(p)).nanmean(dim)))\n",
    "\n",
    "\n",
    "# Assuming the flipper efficiency is wavelength independent (as is the case in this simulation) we can ignore the other parameters\n",
    "polarizer_efficiency = weighted_mean(calibration.Pp, 'blade')\n",
    "analyzer_efficiency = weighted_mean(calibration.Ap, 'blade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "polarizer_efficiency.plot(title='Polarizer efficiency') + analyzer_efficiency.plot(title='Analyzer efficiency')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Finally the calibration curves are used to fit quadratic polynomials that approximate the polarization efficiency as functions of wavelength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def efficiency_model(wavelength, a, b, c):\n",
    "    '''The polarization efficiency of the analyzer and the polarizer\n",
    "    is modeled as a quadratic polynomial'''\n",
    "    return a * wavelength**2 + b * wavelength + c\n",
    "\n",
    "\n",
    "def fit_model_to_efficiency(efficiency):\n",
    "    da = efficiency.copy()\n",
    "    da.coords['wavelength'] = sc.midpoints(da.coords['wavelength'])\n",
    "    par, _ = sc.curve_fit(\n",
    "        ['wavelength'],\n",
    "        efficiency_model,\n",
    "        da,\n",
    "        p0={\n",
    "            'a': sc.scalar(1., unit='1/angstrom**2'),\n",
    "            'b': sc.scalar(1., unit='1/angstrom'),\n",
    "            'c': sc.scalar(1., unit='dimensionless')\n",
    "        }\n",
    "    )\n",
    "    return {k: sc.values(p.data) for k, p in par.items()}\n",
    "\n",
    "\n",
    "sc.plot({\n",
    "    'fit': sc.DataArray(\n",
    "        efficiency_model(\n",
    "            polarizer_efficiency.coords['wavelength'],\n",
    "            **fit_model_to_efficiency(polarizer_efficiency)\n",
    "        ),\n",
    "        coords=polarizer_efficiency.coords\n",
    "    ),\n",
    "    'efficiency': polarizer_efficiency\n",
    "}, title='polarizer') + sc.plot({\n",
    "    'fit': sc.DataArray(\n",
    "        efficiency_model(\n",
    "            analyzer_efficiency.coords['wavelength'],\n",
    "            **fit_model_to_efficiency(analyzer_efficiency)\n",
    "        ),\n",
    "        coords=analyzer_efficiency.coords\n",
    "    ),\n",
    "    'efficiency': analyzer_efficiency\n",
    "}, title='analyzer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "In the polarization correction workflow we can use either the obtained calibration values directly (as a lookup table in wavelength) or we can use the polynomial curves to compute polarization efficiencies as functions of wavelength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pwf = PolarizationAnalysisWorkflow(polarizer_workflow=SupermirrorWorkflow(), analyzer_workflow=SupermirrorWorkflow())\n",
    "\n",
    "# To do the calibration using a lookup table - uncomment these lines\n",
    "#pwf[SupermirrorEfficiencyFunction[Polarizer]] = EfficiencyLookupTable(polarizer_efficiency)\n",
    "#pwf[SupermirrorEfficiencyFunction[Analyzer]] = EfficiencyLookupTable(analyzer_efficiency)\n",
    "\n",
    "# To do the calibration using the polynomial approximation - uncomment these lines\n",
    "pwf[SupermirrorEfficiencyFunction[Polarizer]] = SecondDegreePolynomialEfficiency(**fit_model_to_efficiency(polarizer_efficiency))\n",
    "pwf[SupermirrorEfficiencyFunction[Analyzer]] = SecondDegreePolynomialEfficiency(**fit_model_to_efficiency(analyzer_efficiency))\n",
    "\n",
    "\n",
    "for i, pols in enumerate((Down, Up)):\n",
    "    for j, anas in enumerate((Down, Up)):\n",
    "        sam = references['supermirror'][2*i + j]\n",
    "        pwf[ReducedSampleDataBySpinChannel[pols, anas]] = sam.assign_coords(wavelength=sc.midpoints(sam.coords['wavelength']))\n",
    "\n",
    "\n",
    "res = pwf.compute(TotalPolarizationCorrectedData)\n",
    "I0 = (res.upup + res.downdown) / 2\n",
    "mask = sc.isnan(I0).sum(('blade', 'wire')) > sc.scalar(0, unit=None)\n",
    "wf[ReducedReference] = I0.assign_masks(nopolcal=mask.data).assign_coords(wavelength=wf.compute(WavelengthBins))\n",
    "\n",
    "# Required to read sample rotation / similar parameters associated with the reference measurement\n",
    "wf[RawDetector] = sc.io.load_hdf5(estia_mcstas_spin_flip_example('supermirror', 'offoff'))\n",
    "\n",
    "sample_name = 'spin_flip_sample'\n",
    "\n",
    "for i, pols in enumerate((Down, Up)):\n",
    "    for j, anas in enumerate((Down, Up)):\n",
    "        w = wf.copy()\n",
    "        w[ReducibleData[SampleRun]] = samples[sample_name][2*i + j]\n",
    "        sam = w.compute(ReflectivityOverQ).bin(wavelength=wf.compute(WavelengthBins)).assign_masks(nopolcal=mask.data)\n",
    "        pwf[ReducedSampleDataBySpinChannel[pols, anas]] = sam.assign_coords(wavelength=sc.midpoints(sam.coords['wavelength']))\n",
    "\n",
    "\n",
    "spin_flip_sample_reflectivity = pwf.compute(TotalPolarizationCorrectedData)\n",
    "\n",
    "\n",
    "sample_name = 'magnetic_supermirror'\n",
    "\n",
    "for i, pols in enumerate((Down, Up)):\n",
    "    for j, anas in enumerate((Down, Up)):\n",
    "        w = wf.copy()\n",
    "        w[ReducibleData[SampleRun]] = samples[sample_name][2*i + j]\n",
    "        sam = w.compute(ReflectivityOverQ).bin(wavelength=wf.compute(WavelengthBins)).assign_masks(nopolcal=mask.data)\n",
    "        pwf[ReducedSampleDataBySpinChannel[pols, anas]] = sam.assign_coords(wavelength=sc.midpoints(sam.coords['wavelength']))\n",
    "\n",
    "\n",
    "magnetic_supermirror_reflectivity = pwf.compute(TotalPolarizationCorrectedData)\n",
    "\n",
    "\n",
    "(sc.plot(\n",
    "    {'Rdd': spin_flip_sample_reflectivity.downdown.sum(('wavelength',)),\n",
    "     'Ruu': spin_flip_sample_reflectivity.upup.sum(('wavelength',)),\n",
    "     'Rdu': spin_flip_sample_reflectivity.downup.sum(('wavelength',)),\n",
    "     'Rud': spin_flip_sample_reflectivity.updown.sum(('wavelength',)),\n",
    "     'True Rdd': Rdown * 0.9,\n",
    "     'True Ruu': Rup * 0.9,\n",
    "     'True Rdu': Rdown * 0.1,\n",
    "    }, norm='log', title='Reflectivity of spin flip sample', vmin=1e-4) +\n",
    "sc.plot(\n",
    "    {'Rdd': magnetic_supermirror_reflectivity.downdown.sum(('wavelength',)),\n",
    "     'Ruu': magnetic_supermirror_reflectivity.upup.sum(('wavelength',)),\n",
    "     'Rdu': magnetic_supermirror_reflectivity.downup.sum(('wavelength',)),\n",
    "     'Rud': magnetic_supermirror_reflectivity.updown.sum(('wavelength',)),\n",
    "     'True Rdd': Rdown,\n",
    "     'True Ru': Rup,\n",
    "     'True Rdu': Rdown * 0.0,\n",
    "    }, norm='log', title='Reflectivity of magnetic supermirror sample', vmin=1e-4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
