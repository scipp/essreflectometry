{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Collimated data reduction for OFFSPEC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "This notebook implements a reduction workflow for reflectometry data collected from the ISIS instrument OFFSPEC using a collimated beam. This workflow implements the same procedure as the corresponding workflow in Mantid, see https://docs.mantidproject.org/nightly/techniques/ISIS_Reflectometry.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from datetime import datetime\n",
    "import platform\n",
    "\n",
    "import scipp as sc\n",
    "from orsopy import fileio\n",
    "\n",
    "from ess import reflectometry, offspec\n",
    "from ess.reflectometry.types import *\n",
    "from ess.offspec.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Loading some data\n",
    "\n",
    "In this example, we load some test data provided by the `offspec` package. We need a sample measurement (the sample is `Air | Si(790 A) | Cu(300 A) | SiO2`) and a direct beam measurement. The latter was obtained by positioning the detector directly in the beam of incident neutrons and moving the sample out of the way. It gives an estimate for the ISIS pulse structure as a function of time-of-flight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = offspec.OffspecWorkflow()\n",
    "wf[Filename[SampleRun]] = offspec.data.offspec_sample_run()\n",
    "wf[Filename[ReferenceRun]] = offspec.data.offspec_direct_beam_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.visualize(ReflectivityOverQ, graph_attr={'rankdir': 'LR'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Populating the ORSO header\n",
    "\n",
    "We will write the reduced data file following the ORSO `.ort`` standard <https://www.reflectometry.org/file_format/specification>`__, to enable a metadata rich header. We will create an empty header and then populate this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### The data source information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = fileio.orso.Orso.empty()\n",
    "\n",
    "header.data_source.owner = fileio.base.Person(\n",
    "    name=\"Joshanial F. K. Cooper\",\n",
    "    affiliation=\"ISIS Neutron and Muon Source\",\n",
    ")\n",
    "header.data_source.experiment = fileio.data_source.Experiment(\n",
    "    title=\"OFFSPEC Sample Data\",\n",
    "    instrument=\"OFFSPEC\",\n",
    "    start_date=\"2020-12-14T10:34:02\",\n",
    "    probe=\"neutron\",\n",
    "    facility=\"RAL/ISIS/OFFSPEC\",\n",
    ")\n",
    "header.data_source.sample = fileio.data_source.Sample(\n",
    "    name=\"QCS sample\",\n",
    "    category=\"gas/solid\",\n",
    "    composition=\"Air | Si(790 A) | Cu(300 A) | SiO2\",\n",
    ")\n",
    "header.data_source.measurement = fileio.data_source.Measurement(\n",
    "    instrument_settings=fileio.data_source.InstrumentSettings(\n",
    "        incident_angle=fileio.base.Value(\n",
    "            wf.compute(DetectorData[SampleRun]).coords[\"theta\"].value,\n",
    "            wf.compute(DetectorData[SampleRun]).coords[\"theta\"].unit\n",
    "        ),\n",
    "        wavelength=None,\n",
    "        polarization=\"unpolarized\",\n",
    "    ),\n",
    "    data_files=[\n",
    "        offspec.data.offspec_sample_run().rsplit(\"/\", 1)[-1],\n",
    "        offspec.data.offspec_direct_beam_run().rsplit(\"/\", 1)[-1],\n",
    "    ],\n",
    "    scheme=\"energy-dispersive\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### The reduction details\n",
    "\n",
    "The `reduction` section can start to be populated also. Entries such as `corrections` will be filled up through the reduction process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "header.reduction.software = fileio.reduction.Software(\n",
    "    name=\"essreflectometry\", version=reflectometry.__version__, platform=platform.platform()\n",
    ")\n",
    "header.reduction.timestamp = datetime.now()  # noqa: DTZ005\n",
    "header.reduction.creator = fileio.base.Person(\n",
    "    name=\"I. D. Scientist\",\n",
    "    affiliation=\"European Spallation Source\",\n",
    "    contact=\"i.d.scientist@ess.eu\",\n",
    ")\n",
    "header.reduction.corrections = []\n",
    "header.reduction.computer = platform.node()\n",
    "header.reduction.script = \"offspec_reduction.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "To ensure that the header object is carried through the process, we assign it to the sample `scipp.DataArray`. The direct beam header object will be overwritten at the normalisation step so we will keep this empty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Determining the region of interest\n",
    "\n",
    "To determine what region of the detector contains the specular peak intensity we plot the intensity distribution of the sample measurement over `spectrum` (detector pixel) and `time-of-flight`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.compute(DetectorData[SampleRun]).hist(tof=50).plot(norm='log') \\\n",
    "+ wf.compute(DetectorData[ReferenceRun]).hist(tof=50).plot(norm='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "The region of interest is set in the workflow by setting `SpectrumLimits`. In this case it seems the specular peak is in the region `[389, 414]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf[SpectrumLimits] = (sc.scalar(389, unit=None), sc.scalar(414, unit=None))\n",
    "header.reduction.corrections += ['region of interest defined as spectrum 389:415']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Coordinate transform graph\n",
    "\n",
    "To compute the wavelength $\\lambda$ we can use a coordinate transform graph. The OFFSPEC graph is the standard reflectometry graph, shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.show_graph(wf.compute(CoordTransformationGraph[SampleRun]), simplified=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Since the direct beam measurement is __not__ a reflectometry measurement, we use the `no_scatter_graph` to convert this to wavelength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.show_graph(wf.compute(CoordTransformationGraph[ReferenceRun]), simplified=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Normalization by monitor\n",
    "It is necessary to normalize the sample and direct beam measurements by the summed monitor counts, which accounts for different lengths of measurement and long-timescale natural variation in the pulse. This will ensure that the final data has the correct scaling when the reflectivity data is normalized. First, we convert the data to wavelength, using the `no_scatter_graph` used previously for the direct beam.\n",
    "\n",
    "The most reliable monitor for the OFFSPEC instrument is 'monitor2' in the file, therefore this is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.compute(MonitorData[SampleRun]).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "A background subtraction is then performed on the monitor data, where the background is taken as any counts at wavelengths greater than 15 Å. We also mask all events in the sample- and direct-beam measurements that fall outside of the wavelength range we expect for the instrument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf[BackgroundMinWavelength] = sc.scalar(15, unit='angstrom')\n",
    "wf[WavelengthBins] = sc.linspace(dim='wavelength', start=2, stop=14, num=2, unit='angstrom')\n",
    "header.reduction.corrections += ['monitor background subtraction, background above 15 Å']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Normalisation of sample by direct beam\n",
    "The sample and direct beam measurements (which have been normalised by monitor counts) are then histogrammed in $Q$ to 100 geometrically spaced points. The histogrammed direct beam is then used to normalised the sample.\n",
    "\n",
    "Importantly, some relevant metadata (including the ORSO header object) is carried over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf[QBins] = sc.geomspace('Q', 0.005, 0.033, 101, unit='1/angstrom')\n",
    "header.reduction.corrections += [\"normalisation by direct beam\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "We will assume a 3 % of $Q$ resolution function to be included in our file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf[QResolution] = 0.03"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Conversion to $Q$\n",
    "This normalised data can then be used to compute the reflectivity as a function of the scattering vector $Q$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "Roq = wf.compute(ReflectivityOverQ).hist()\n",
    "Roq.plot(norm='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## Saving the scipp-reduced data as .ort\n",
    "We constructed the ORSO header through the reduction process. We can now make use of this when we save our .ort file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "And it is necessary to add the column for our uncertainties, which details the **meaning** of the uncertainty values we have given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "header.columns.append(fileio.base.ErrorColumn(error_of='R', error_type='uncertainty', value_is='sigma'))\n",
    "header.columns.append(fileio.base.ErrorColumn(error_of='Q', error_type='resolution', value_is='sigma'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "Finally, we can save the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ds = fileio.orso.OrsoDataset(\n",
    "    header,\n",
    "    np.array([\n",
    "        sc.midpoints(Roq.coords['Q']).values,\n",
    "        Roq.data.values,\n",
    "        sc.stddevs(Roq.data).values,\n",
    "        Roq.coords['Q_resolution'].values]\n",
    "    ).T\n",
    ")\n",
    "\n",
    "fileio.save_orso([ds], 'offspec.ort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 50 offspec.ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "header.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
