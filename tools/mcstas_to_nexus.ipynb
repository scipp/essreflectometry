{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# McStas to NeXus for ESTIA\n",
    "\n",
    "This notebook converts data from a McStas simulation output (`.h5` filetype) to a NeXus file that uses a file for the Estia instrument (written by CODA) as a template for the geometry information.\n",
    "\n",
    "It adds\n",
    "\n",
    "* events to the `multiblade_detector` detector,\n",
    "* a single value to the `proton_current` log,\n",
    "* a single detector rotation value to the `detector_rotation` log,\n",
    "* a single sample rotation value to the `sample_rotation` log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipp as sc\n",
    "import h5py\n",
    "import shutil\n",
    "\n",
    "from ess.estia.mcstas import parse_events_h5\n",
    "from ess.estia.load import load_mcstas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_dataset(entry, name, values):\n",
    "    attrs = dict(entry[name].attrs)\n",
    "    del entry[name]\n",
    "    dset = entry.create_dataset(name, data=values)\n",
    "    dset.attrs.update(attrs)\n",
    "\n",
    "\n",
    "def mcstas_to_nexus(\n",
    "    mcstas_data_file: str,\n",
    "    template_nexus_file: str,\n",
    "    outfile: str,\n",
    "    nevents_per_weight: float = 1/3,\n",
    "):\n",
    "    \"\"\"\n",
    "    Store the events from a McStas Estia simulation in a NeXus CODA file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mcstas_data_file:\n",
    "        Data file containing simulated McStas events.\n",
    "    template_nexus_file:\n",
    "        NeXus file containing geometry and instrument info, used as a template.\n",
    "    outfile:\n",
    "        Output file to be written.\n",
    "    nevents:\n",
    "        Number of events to have in the output file\n",
    "        (events are sampled from the probabilities of the mcstas events).\n",
    "    \"\"\"\n",
    "    detector_entry_path = '/entry/instrument/multiblade_detector'\n",
    "\n",
    "    with h5py.File(template_nexus_file, \"r\") as f:\n",
    "        det_numbers = f[f\"{detector_entry_path}/detector_number\"][()]\n",
    "\n",
    "    with h5py.File(mcstas_data_file) as f:\n",
    "        events = parse_events_h5(f,  events_to_sample_per_unit_weight=nevents_per_weight)\n",
    "    binned = load_mcstas(events).transpose(['strip', 'blade', 'wire', ])\n",
    "\n",
    "    toa = (binned.bins.coords[\"event_time_zero\"] + binned.bins.coords[\"event_time_offset\"]).bins.concat().value\n",
    "\n",
    "    det_numbers_matching_order_of_binned = det_numbers.reshape(binned.shape)\n",
    "    det_numbers_matching_order_of_binned = det_numbers_matching_order_of_binned[::-1, ::-1, ::-1]\n",
    "    # IMPORTANT! we need to sort the arrays below according to toa,\n",
    "    # so that the event_index does not get messed up!\n",
    "    event_id = sc.sort(\n",
    "        (\n",
    "            sc.bins_like(binned, sc.array(dims=binned.dims, values=det_numbers_matching_order_of_binned))\n",
    "            .bins.concat()\n",
    "            .value\n",
    "        ),\n",
    "        key=toa,\n",
    "    )\n",
    "    event_time_zero = sc.sort(binned.bins.coords[\"event_time_zero\"].bins.concat().value, key=toa)\n",
    "    event_time_offset = sc.sort(binned.bins.coords[\"event_time_offset\"].bins.concat().value, key=toa)\n",
    "\n",
    "    event_index = sc.DataArray(\n",
    "        data=sc.ones_like(event_time_offset),\n",
    "        coords={\"event_time_zero\": event_time_zero},\n",
    "    ).group(\"event_time_zero\")\n",
    "\n",
    "    event_index = sc.cumsum(event_index.bins.size())\n",
    "    event_index.values = np.concatenate([[0], event_index.values[:-1]])\n",
    "\n",
    "    shutil.copyfile(template_nexus_file, outfile)\n",
    "\n",
    "    with h5py.File(outfile, \"r+\") as f:\n",
    "\n",
    "        # TODO: remove this when the files is fixed\n",
    "        # Fix error in Nexus file\n",
    "        f['/entry/instrument/source/transformations/location'][()] = -35.0512\n",
    "\n",
    "        detector_rotation = f[f\"{detector_entry_path}/transformations/detector_rotation\"]\n",
    "        replace_dataset(\n",
    "            detector_rotation,\n",
    "            name=\"value\",\n",
    "            values=[\n",
    "                binned\n",
    "                    .coords['detector_rotation']\n",
    "                    .to(unit=detector_rotation['value'].attrs['units'])\n",
    "                    .value\n",
    "            ]\n",
    "        )\n",
    "        replace_dataset(\n",
    "            detector_rotation,\n",
    "            name=\"time\",\n",
    "            values=[\n",
    "                event_time_zero\n",
    "                    .min()\n",
    "                    .to(unit=detector_rotation['time'].attrs['units'])\n",
    "                    .value\n",
    "                    .astype('uint64')\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        sample = f[\"entry/sample\"]\n",
    "        sample_rotation = sample.create_group('sample_rotation')\n",
    "        sample_rotation.attrs['NX_class'] = 'NXlog'\n",
    "        sample_rotation.create_dataset(\n",
    "            'value',\n",
    "            data=[\n",
    "                binned\n",
    "                .coords['sample_rotation']\n",
    "                .to(unit='deg')\n",
    "                .value\n",
    "                .astype('float64')\n",
    "            ],\n",
    "        )\n",
    "        sample_rotation['value'].attrs['units'] = 'degrees'\n",
    "        sample_rotation.create_dataset(\n",
    "            'time',\n",
    "            data=[\n",
    "                event_time_zero\n",
    "                    .min()\n",
    "                    .to(unit='ns')\n",
    "                    .value\n",
    "                    .astype('uint64')\n",
    "            ],\n",
    "        )\n",
    "        sample_rotation['time'].attrs['units'] = 'ns'\n",
    "\n",
    "        f[\"entry/neutron_prod_info/pulse_charge/value\"][:] = 1.\n",
    "\n",
    "        event_data = f[f\"{detector_entry_path}/event_data\"]\n",
    "        replace_dataset(event_data, name=\"event_id\", values=event_id.values.astype('uint32'))\n",
    "        replace_dataset(\n",
    "            event_data,\n",
    "            name=\"event_time_offset\",\n",
    "            values=event_time_offset.to(\n",
    "                unit=event_data[\"event_time_offset\"].attrs[\"units\"], copy=False\n",
    "            ).values.astype('uint32'),\n",
    "        )\n",
    "        replace_dataset(event_data, name=\"event_index\", values=event_index.values.astype('uint64'))\n",
    "        replace_dataset(\n",
    "            event_data,\n",
    "            name=\"event_time_zero\",\n",
    "            values=event_index.coords[\"event_time_zero\"]\n",
    "            .to(unit=event_data[\"event_time_zero\"].attrs[\"units\"], copy=False)\n",
    "            .values.astype('uint64'),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Generate nexus files from a Nexus template and McStas events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ess.estia.data import estia_mcstas_example\n",
    "\n",
    "\n",
    "mcstas_to_nexus(\n",
    "    mcstas_data_file=estia_mcstas_example('reference'),\n",
    "    template_nexus_file=\"/home/johannes/Downloads/estia_999999_00008786.hdf\",\n",
    "    outfile='reference.nx',\n",
    "    nevents_per_weight=1,\n",
    ")\n",
    "\n",
    "for i, example in enumerate(estia_mcstas_example('Ni/Ti-multilayer')):\n",
    "    mcstas_to_nexus(\n",
    "        mcstas_data_file=example,\n",
    "        template_nexus_file=\"/home/johannes/Downloads/estia_999999_00008786.hdf\",\n",
    "        outfile=f'niti_ml_{i}.nx',\n",
    "        nevents_per_weight=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Detector view from the created nexus file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ess.estia import EstiaWorkflow\n",
    "from ess.reflectometry.types import *\n",
    "import scippneutron as scn\n",
    "\n",
    "wf = EstiaWorkflow()\n",
    "wf[Filename[SampleRun]] = 'niti_ml_0.nx'\n",
    "\n",
    "scn.instrument_view(wf.compute(RawDetector[SampleRun]).hist(), pixel_size=3, norm='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Compute reflectivity curves from the nexus files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ess.estia.data import estia_mcstas_example, estia_tof_lookup_table\n",
    "from ess.estia import EstiaWorkflow\n",
    "from ess.reflectometry.types import *\n",
    "from ess.reflectometry import supermirror\n",
    "\n",
    "\n",
    "wf = EstiaWorkflow()\n",
    "wf[Filename[ReferenceRun]] = 'reference.nx'\n",
    "wf[YIndexLimits] = sc.scalar(35), sc.scalar(64)\n",
    "wf[ZIndexLimits] = sc.scalar(0), sc.scalar(48 * 32)\n",
    "wf[BeamDivergenceLimits] = sc.scalar(-0.75, unit='deg'), sc.scalar(0.75, unit='deg')\n",
    "\n",
    "wf[supermirror.MValue] = sc.scalar(5, unit=sc.units.dimensionless)\n",
    "wf[supermirror.CriticalEdge] = sc.scalar(float('inf'), unit='1/angstrom')\n",
    "wf[supermirror.Alpha] = sc.scalar(0.25 / 0.088, unit=sc.units.angstrom)\n",
    "\n",
    "wf[DetectorSpatialResolution[RunType]] = 0.0025 * sc.units.m\n",
    "\n",
    "# Configure the binning of intermediate and final results:\n",
    "wf[WavelengthBins] = sc.geomspace('wavelength', 3.5, 12, 2001, unit='angstrom')\n",
    "wf[QBins] = sc.geomspace('Q', 0.01, 0.5, 401, unit='1/angstrom')\n",
    "\n",
    "wf[TimeOfFlightLookupTableFilename] = estia_tof_lookup_table()\n",
    "\n",
    "\n",
    "wf[ProtonCurrent[SampleRun]] = sc.DataArray(\n",
    "    sc.array(dims=('time',), values=[]),\n",
    "    coords={'time': sc.array(dims=('time',), values=[], unit='s')})\n",
    "wf[ProtonCurrent[ReferenceRun]] = sc.DataArray(\n",
    "    sc.array(dims=('time',), values=[]),\n",
    "    coords={'time': sc.array(dims=('time',), values=[], unit='s')})\n",
    "\n",
    "wf.visualize(ReflectivityOverQ, graph_attr={\"rankdir\": \"LR\"}, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "from ess.reflectometry.tools import batch_compute\n",
    "params = {\n",
    "    str(i): {\n",
    "        Filename[SampleRun]: f'niti_ml_{i}.nx'\n",
    "    }\n",
    "    for i in range(4)\n",
    "}\n",
    "\n",
    "batch_compute(\n",
    "    wf,\n",
    "    params,\n",
    "    ReflectivityOverQ,\n",
    "    #scale_to_overlap=True\n",
    ").hist().plot(norm='log', vmin=1e-7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
